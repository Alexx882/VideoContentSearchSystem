{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier with CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "BATCH_SIZE = 128\n",
    "N_EPOCHS = 5\n",
    "IMG_HEIGHT = 256\n",
    "IMG_WIDTH = 256\n",
    "IMG_CHANNELS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "The used dataset is the iconic MNIST database of handwritten digits. As the distribution of training and test set is not .7 and .3 as needed for the assignment, some of the training data was randomly moved to the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Reshape dataset to match Keras API\n",
    "# (size, x, y, channels)\n",
    "x_train = x_train.reshape(x_train.shape[0], IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
    "x_test = x_test.reshape(x_test.shape[0], IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_test = np.append(x_test, x_train[49000:], axis=0)\n",
    "x_train = x_train[:49000]\n",
    "\n",
    "y_test = np.append(y_test, y_train[49000:], axis=0)\n",
    "y_train = y_train[:49000]\n",
    "\n",
    "print(f'x train: {len(x_train)}, x test: {len(x_test)}')\n",
    "print(f'y train: {len(y_train)}, y test: {len(y_test)}')\n",
    "total = len(x_train)+len(x_test)\n",
    "print(f'training set part: {len(x_train)/total}, test set part: {len(x_test)/total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_length = len(x_train)\n",
    "test_length = len(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Sophisticated Dataset\n",
    "To detect \"real\" settings a more sophisticated dataset was used. There, the labels have to be converted manually to match the expected input for the neural network.\n",
    "For this, the dataset generator is adapted to load the images from file, where labels are indicated by folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_path = '../VOCdevkit/VOC2012/prepared'\n",
    "if not os.path.exists(base_path):\n",
    "    raise IOError('Image folder does not exist')\n",
    "\n",
    "soph_dataset_training_path = os.path.normpath(os.path.join(base_path,'training'))\n",
    "soph_dataset_test_path = os.path.normpath(os.path.join(base_path,'test'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Generator with Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data_gen = ImageDataGenerator(\n",
    "    # rescale pixel values [0, 255] to [0, 1]\n",
    "    rescale=1./255, \n",
    "    # augmentation:\n",
    "    ## allow some rotation \n",
    "    rotation_range=45,\n",
    "    ## allow to shift whole image\n",
    "    width_shift_range=.2,\n",
    "    height_shift_range=.2,\n",
    "    fill_mode=\"nearest\",\n",
    "    ## allow some zoom\n",
    "    zoom_range=.15\n",
    ") \\\n",
    ".flow_from_directory(\n",
    "    soph_dataset_training_path,\n",
    "    class_mode='sparse',\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "# .flow(x_train, y_train, batch_size=BATCH_SIZE)\n",
    "\n",
    "test_data_gen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    "    # dont apply augmentation in test set\n",
    ") \\\n",
    ".flow_from_directory(\n",
    "    soph_dataset_test_path,\n",
    "    class_mode='sparse',\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "# .flow(x_test, y_test, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_length = 4098 \n",
    "test_length = 1764"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotImages(title, images_arr, subtitles=None):\n",
    "    fig, axes = plt.subplots(1, len(images_arr))\n",
    "    fig.suptitle(title, fontsize=20, y=.80)\n",
    "\n",
    "    axes = axes.flatten()\n",
    "    for i in range(len(images_arr)):\n",
    "        img = images_arr[i]\n",
    "        ax = axes[i]\n",
    "        subtitle = subtitles[i] if subtitles is not None else None\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "        ax.set_title(subtitle)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_elements = 5\n",
    "augmented_images, y = next(train_data_gen)\n",
    "plotImages('Some training images', augmented_images[:vis_elements].reshape(vis_elements, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "\n",
    "augmented_images = [train_data_gen[0][0][0].reshape(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS) for i in range(vis_elements)]\n",
    "plotImages('Augmentation examples', augmented_images)\n",
    "\n",
    "augmented_images = [train_data_gen[0][0][1].reshape(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS) for i in range(vis_elements)]\n",
    "plotImages('More augmentation examples', augmented_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# build the layers\n",
    "model = Sequential([\n",
    "    # convolution over image with \n",
    "    ## nr of filters aka depth of the resulting convolution result\n",
    "    ## kernel size for the convolution\n",
    "    ## padding if the kernel is placed at the borders\n",
    "    ## activation function of the result\n",
    "    ## shape of the input (as it's the first layer)\n",
    "    Conv2D(16, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)),\n",
    "    # pooling for the results from previous layer by taking max value with pooling size (2, 2)\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    # flattens the previous result into one dimension (concat of multidimensional results)\n",
    "    Flatten(),\n",
    "    # fully connected layer\n",
    "    Dense(512, activation='relu'),\n",
    "    # final fully connected layer with \n",
    "    ## number of output values = nr of classes\n",
    "    ## activation function is softmax to create probabilities\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# compile the architecture\n",
    "model.compile(\n",
    "              # optimizer for applying updates\n",
    "              optimizer='adam',\n",
    "              # sparse categorical instead of binary as we have more than two classes\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              # the metrics to show while training and on evaluations\n",
    "              metrics=['accuracy']\n",
    "              )\n",
    "\n",
    "# print a summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function\n",
    "The loss function is used to determine how far away the generated results during training are compared to ground truth. In an optimal case, all predictions should match the given labels which results in a loss of 0.\n",
    "#### Binary Crossentropy\n",
    "This loss function calculates the loss for two classes (true or false). If the real value is 1 the loss is log(P(1)). If the real value is 0 the loss is log(1-P(1)) = log(P(0)). P(1) is the predicted probability for the current input to be 1. The individual losses are averaged over all training inputs. As the result of log(x) with 1>x>0 is negative the overall result is multiplied by -1. <br/>\n",
    "Using the log function matches the formula for entropy, with the difference that this one adds the log probabilities for all classes and does not calculate the average.\n",
    "#### Categorical Crossentropy \n",
    "I used sparse categorical crossentropy as this also works with more than two classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "                    # training data provided by generator\n",
    "                    train_data_gen,\n",
    "                    # steps per epoch calculated that all training data is seen once per epoch\n",
    "                    steps_per_epoch=training_length/BATCH_SIZE,\n",
    "                    # number of epochs\n",
    "                    epochs=N_EPOCHS,\n",
    "                    # test data to visualize results later in plot\n",
    "                    validation_data=test_data_gen,\n",
    "                    # steps after each epoch for test data\n",
    "                    validation_steps=test_length/BATCH_SIZE\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('voc2012.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_test, y_test = next(test_data_gen)\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs_range = range(N_EPOCHS)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Test Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Test Loss')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Test Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Test Accuracy')\n",
    "\n",
    "# plt.savefig('history.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualized results here are final loss and accuracy after each epoch. <br />\n",
    "As the training improves the prediction results, the resulting loss decreases. Simultaneously, the accuracy improves with better predictions.\n",
    "\n",
    "This is the result with a lot of augmented data. The accuracy of the test set is even better than the one from the training set, as it is less noisy and therefore easier to classify. Mentionable here is also the (almost) constant increase in accuracy which means there is not much overfitting.\n",
    "\n",
    "Before the training data augmentation, loss and accuracy had a lot of large hops from better to worse again which can be a sign of overfitting. Also the test set accuracy was constantly worse than the training set accuracy. Dropout layers did not contribute much to the final result, so they were removed in favor of a simpler network architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "x = [(x_test[i], y_test[i], np.argmax(y_pred[i])) for i in range(len(y_pred)) if y_test[i] != np.argmax(y_pred[i])][:5]\n",
    "\n",
    "plotImages('Incorrect prediction examples', \n",
    "           [f.reshape(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS) for f, _, _ in x], \n",
    "           subtitles=[f\"Predicted {t}\\n instead of {s}\" for _, s, t in x]\n",
    "           )"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}